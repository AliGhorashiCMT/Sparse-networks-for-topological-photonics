{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33a7ff4-b0b4-4366-b732-986dac3993a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan.hypothesis import *\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from kan import *\n",
    "import h5py\n",
    "import copy\n",
    "import sympy as sp\n",
    "dtype = torch.get_default_dtype()\n",
    "from sympy import latex\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822a71f-f6c0-4e51-b710-2cd0e0168abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./\"\n",
    "filename = \"sg2-data.h5\"\n",
    "checkpoint_dir = \"./saved_models/\"\n",
    "log_dir = './logs/'\n",
    "band_idx = 0\n",
    "gidxs = [1, 2, 3, 4]\n",
    "only_obstructed = False\n",
    "only_topological = False\n",
    "binary_classification = False#True\n",
    "no_penalize_last = True\n",
    "bias = False\n",
    "numrs = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b995bd40-9c17-45f5-a84b-cb28dce15506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file keys:  <KeysViewHDF5 ['epsilon_Gs-gidx=1', 'epsilon_Gs-gidx=2', 'epsilon_Gs-gidx=3', 'epsilon_Gs-gidx=4', 'frequencies-gidx=1-mode=tm', 'frequencies-gidx=2-mode=tm', 'frequencies-gidx=3-mode=tm', 'frequencies-gidx=4-mode=tm', 'symmetry-gidx=1-mode=tm', 'symmetry-gidx=2-mode=tm', 'symmetry-gidx=3-mode=tm', 'symmetry-gidx=4-mode=tm']>\n"
     ]
    }
   ],
   "source": [
    "file = h5py.File(data_dir + filename, 'r')\n",
    "print(\"file keys: \", file['sg2/1/'].keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c7bdf5-cbae-4dac-a346-65d07365cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nGs = 10\n",
    "gidxs = [1, 2, 3, 4]\n",
    "wps = ['1a', '1b', '1c', '1d']\n",
    "wps2 = ['1a', '1c', '1b', '1d'] # switch 1b and 1c due to convention of how Gvectors are stored\n",
    "\n",
    "symmetry_data = torch.zeros(10000 * len(gidxs) * len(wps))\n",
    "input_data = torch.zeros(10000 * len(gidxs) * len(wps), nGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ee110a-4d39-4101-8c27-9c5c6a462bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyckoff index: 0\n",
      "gidx: 1\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 2\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 3\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 4\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Wyckoff index: 1\n",
      "gidx: 1\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 2\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 3\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 4\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Wyckoff index: 2\n",
      "gidx: 1\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 2\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 3\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 4\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Wyckoff index: 3\n",
      "gidx: 1\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 2\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 3\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "gidx: 4\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "for (widx, (wp1, wp2)) in enumerate(zip(wps, wps2)):\n",
    "    print(f\"Wyckoff index: {widx}\")\n",
    "    sym_vec_phases = file[f'sg2/symmetry_vector_phases/{wp1}'][()]\n",
    "    epsilon_G_phases = file[f'sg2/epsilon_G_phases/{wp2}'][()].real\n",
    "    for gidx in gidxs:\n",
    "        print(f\"gidx: {gidx}\")\n",
    "        for id in range(1, 10001):\n",
    "            real_id = (id-1) + (gidx-1)*10000 + len(gidxs)*10000*widx\n",
    "            if (id % 1000 == 0): \n",
    "                print(id)\n",
    "            symmetry_before_aug = file[f'sg2/{id}/symmetry-gidx={gidx}-mode=tm'][()][band_idx]\n",
    "            if band_idx == 0:\n",
    "                symmetry_data[real_id] =  sym_vec_phases[symmetry_before_aug] - 8\n",
    "            else: \n",
    "                symmetry_data[real_id] =  sym_vec_phases[symmetry_before_aug] \n",
    "\n",
    "            fourier_data_before_aug = file[f'sg2/{id}/epsilon_Gs-gidx={gidx}'][()][0:nGs].real\n",
    "            fourier_data = fourier_data_before_aug * epsilon_G_phases\n",
    "            input_data[real_id, :] = torch.tensor([*fourier_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83134046-6dc1-449b-b9e3-31db4c8718cd",
   "metadata": {},
   "source": [
    "### Below, we make $2\\times 11$ datasets, the first seven corresponding to training tests of sizes: $8, 16, 32, 64, 128, 256, 512$ and the second half having the same data but with augmentations (so four times the amount of data in each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746130f2-01d5-48f5-b187-be5850d63bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs_no_aug = []\n",
    "training_inputs_aug = []\n",
    "\n",
    "training_labels_no_aug = []\n",
    "training_labels_aug = []\n",
    "\n",
    "training_set_sizes = np.array([8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ebf8e0-058f-4fc0-9673-cfc9dd263a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000 * len(gidxs)\n",
    "for s in training_set_sizes:\n",
    "    shuffled_indices_no_aug = torch.randperm(N)[0:s] # from 0 to 40,000\n",
    "    shuffled_indices_aug = torch.cat([shuffled_indices_no_aug + i*N for i in range(0, 4)])\n",
    "\n",
    "    shuffled_indices_aug = shuffled_indices_aug[torch.randperm(4*s)]\n",
    "    \n",
    "    training_inputs_no_aug.append(input_data[shuffled_indices_no_aug, :])\n",
    "    training_inputs_aug.append(input_data[shuffled_indices_aug, :])\n",
    "\n",
    "    training_labels_no_aug.append(symmetry_data[shuffled_indices_no_aug])\n",
    "    training_labels_aug.append(symmetry_data[shuffled_indices_aug])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db07b52-a3c6-4974-9b3d-aba2eea492b3",
   "metadata": {},
   "source": [
    "### Check that augmented datasets correspond correctly to un-augmented datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bcef5c7-1668-43ce-86be-a6963758aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique data elements given by:  8\n",
      "Number of unique data elements given by:  16\n",
      "Number of unique data elements given by:  32\n",
      "Number of unique data elements given by:  64\n",
      "Number of unique data elements given by:  128\n",
      "Number of unique data elements given by:  256\n",
      "Number of unique data elements given by:  512\n",
      "Number of unique data elements given by:  1024\n",
      "Number of unique data elements given by:  2048\n",
      "Number of unique data elements given by:  4096\n",
      "Number of unique data elements given by:  8192\n"
     ]
    }
   ],
   "source": [
    "for training_input_aug in training_inputs_aug:\n",
    "    num_unique_elements = training_input_aug.abs().unique(dim=0).shape[0]\n",
    "    print(\"Number of unique data elements given by: \", num_unique_elements )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459c10c-48f8-4d84-a2ea-ac0543787b92",
   "metadata": {},
   "source": [
    "### Run without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "55eef17a-6460-4d87-890c-da10290d8845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input size:  torch.Size([8, 10])\n",
      "Training label size:  torch.Size([8])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.22e-04 | test_loss: 4.05e+00 | reg: 3.96e+02 | : 100%|█| 100/100 [00:09<00:00, 10.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  14.69\n",
      "Training input size:  torch.Size([16, 10])\n",
      "Training label size:  torch.Size([16])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 0.00e+00 | test_loss: 5.25e+00 | reg: 6.53e+02 | : 100%|█| 100/100 [00:08<00:00, 11.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  27.84\n",
      "Training input size:  torch.Size([32, 10])\n",
      "Training label size:  torch.Size([32])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 0.00e+00 | test_loss: 3.95e+00 | reg: 7.32e+02 | : 100%|█| 100/100 [00:09<00:00, 10.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  30.25\n",
      "Training input size:  torch.Size([64, 10])\n",
      "Training label size:  torch.Size([64])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 0.00e+00 | test_loss: 3.71e+00 | reg: 7.45e+02 | : 100%|█| 100/100 [00:09<00:00, 10.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  48.72\n",
      "Training input size:  torch.Size([128, 10])\n",
      "Training label size:  torch.Size([128])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.18e-04 | test_loss: 1.56e+00 | reg: 6.18e+02 | : 100%|█| 100/100 [00:09<00:00, 10.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  74.1\n",
      "Training input size:  torch.Size([256, 10])\n",
      "Training label size:  torch.Size([256])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.21e-04 | test_loss: 9.15e-01 | reg: 9.25e+02 | : 100%|█| 100/100 [00:07<00:00, 13.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  91.44\n",
      "Training input size:  torch.Size([512, 10])\n",
      "Training label size:  torch.Size([512])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.35e-03 | test_loss: 8.20e-01 | reg: 1.05e+03 | : 100%|█| 100/100 [00:07<00:00, 13.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  94.26\n",
      "Training input size:  torch.Size([1024, 10])\n",
      "Training label size:  torch.Size([1024])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 2.85e-05 | test_loss: 8.31e-01 | reg: 9.80e+02 | : 100%|█| 100/100 [00:09<00:00, 10.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  95.58\n",
      "Training input size:  torch.Size([2048, 10])\n",
      "Training label size:  torch.Size([2048])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.40e-04 | test_loss: 8.00e-01 | reg: 1.06e+03 | : 100%|█| 100/100 [00:08<00:00, 12.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  96.72\n",
      "Training input size:  torch.Size([4096, 10])\n",
      "Training label size:  torch.Size([4096])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.41e-05 | test_loss: 6.02e-01 | reg: 9.83e+02 | : 100%|█| 100/100 [00:11<00:00,  8.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  98.24\n",
      "Training input size:  torch.Size([8192, 10])\n",
      "Training label size:  torch.Size([8192])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 2.19e-05 | test_loss: 6.91e-01 | reg: 1.50e+03 | : 100%|█| 100/100 [00:12<00:00,  7.81"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  98.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_accs_no_aug = []\n",
    "testing_accs_no_aug = []\n",
    "\n",
    "for (training_input_no_aug, training_label_no_aug) in zip(training_inputs_no_aug, training_labels_no_aug):\n",
    "    print(\"Training input size: \", training_input_no_aug.shape)\n",
    "    print(\"Training label size: \", training_label_no_aug.shape)\n",
    "\n",
    "    dataset_kan = {}\n",
    "    nGs = 10\n",
    "    nGstart = 1\n",
    "    \n",
    "    dataset_kan['train_input'] = training_input_no_aug[:, [*range(nGstart, nGs)]].to(device)\n",
    "    dataset_kan['train_label'] = training_label_no_aug.long().to(device)\n",
    "    \n",
    "    # Put all data in test datasets\n",
    "    dataset_kan['test_input'] = input_data[:, [*range(nGstart, nGs)]].to(device)\n",
    "    dataset_kan['test_label'] = symmetry_data.long().to(device)\n",
    "    \n",
    "    n_class = 16\n",
    "    if band_idx == 0:\n",
    "        n_class = 8\n",
    "    model = KAN(width=[9, 24, n_class], grid=5, k=1, seed=1, device=device)\n",
    "    lr = 1\n",
    "    def train_acc():\n",
    "        return torch.mean((torch.argmax(model(dataset_kan['train_input']), dim=1) == dataset_kan['train_label']).type(dtype))\n",
    "    \n",
    "    def test_acc():\n",
    "        return torch.mean((torch.argmax(model(dataset_kan['test_input']), dim=1) == dataset_kan['test_label']).type(dtype))\n",
    "        \n",
    "    results = model.fit(dataset_kan, opt=\"LBFGS\", steps=100, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss(), lr=lr);\n",
    "    model.attribute()\n",
    "    print(\"Train accuracy: \", round(results['train_acc'][-1]*100, 2),  \" Test accuracy: \", round(results['test_acc'][-1]*100, 2))\n",
    "    training_accs_no_aug.append(round(results['train_acc'][-1]*100, 2))\n",
    "    testing_accs_no_aug.append(round(results['test_acc'][-1]*100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78db0d91-c686-4b26-a5eb-56c8d46582b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input size:  torch.Size([32, 10])\n",
      "Training label size:  torch.Size([32])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 0.00e+00 | test_loss: 2.79e+00 | reg: 5.41e+02 | : 100%|█| 100/100 [00:09<00:00, 11.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  35.37\n",
      "Training input size:  torch.Size([64, 10])\n",
      "Training label size:  torch.Size([64])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 4.32e-05 | test_loss: 2.29e+00 | reg: 8.54e+02 | : 100%|█| 100/100 [00:09<00:00, 11.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  68.66\n",
      "Training input size:  torch.Size([128, 10])\n",
      "Training label size:  torch.Size([128])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 0.00e+00 | test_loss: 1.77e+00 | reg: 8.03e+02 | : 100%|█| 100/100 [00:09<00:00, 10.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  78.71\n",
      "Training input size:  torch.Size([256, 10])\n",
      "Training label size:  torch.Size([256])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.74e-05 | test_loss: 8.73e-01 | reg: 5.95e+02 | : 100%|█| 100/100 [00:08<00:00, 11.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  91.34\n",
      "Training input size:  torch.Size([512, 10])\n",
      "Training label size:  torch.Size([512])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 7.78e-05 | test_loss: 9.70e-01 | reg: 1.12e+03 | : 100%|█| 100/100 [00:07<00:00, 13.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  93.34\n",
      "Training input size:  torch.Size([1024, 10])\n",
      "Training label size:  torch.Size([1024])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.41e-04 | test_loss: 7.14e-01 | reg: 9.28e+02 | : 100%|█| 100/100 [00:08<00:00, 12.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  95.89\n",
      "Training input size:  torch.Size([2048, 10])\n",
      "Training label size:  torch.Size([2048])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.96e-05 | test_loss: 7.73e-01 | reg: 9.27e+02 | : 100%|█| 100/100 [00:09<00:00, 10.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  96.51\n",
      "Training input size:  torch.Size([4096, 10])\n",
      "Training label size:  torch.Size([4096])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.59e-04 | test_loss: 7.57e-01 | reg: 1.17e+03 | : 100%|█| 100/100 [00:08<00:00, 11.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  98.47\n",
      "Training input size:  torch.Size([8192, 10])\n",
      "Training label size:  torch.Size([8192])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 4.91e-05 | test_loss: 6.52e-01 | reg: 1.31e+03 | : 100%|█| 100/100 [00:11<00:00,  8.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  98.46\n",
      "Training input size:  torch.Size([16384, 10])\n",
      "Training label size:  torch.Size([16384])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.75e-05 | test_loss: 3.88e-01 | reg: 1.22e+03 | : 100%|█| 100/100 [00:16<00:00,  6.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  99.21\n",
      "Training input size:  torch.Size([32768, 10])\n",
      "Training label size:  torch.Size([32768])\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 4.73e-03 | test_loss: 2.78e-01 | reg: 1.20e+03 | : 100%|█| 100/100 [00:31<00:00,  3.15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train accuracy:  100.0  Test accuracy:  99.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_accs_aug = []\n",
    "testing_accs_aug = []\n",
    "\n",
    "for (training_input_aug, training_label_aug) in zip(training_inputs_aug, training_labels_aug):\n",
    "    print(\"Training input size: \", training_input_aug.shape)\n",
    "    print(\"Training label size: \", training_label_aug.shape)\n",
    "\n",
    "    dataset_kan = {}\n",
    "    nGs = 10\n",
    "    nGstart = 1\n",
    "    \n",
    "    dataset_kan['train_input'] = training_input_aug[:, [*range(nGstart, nGs)]].to(device)\n",
    "    dataset_kan['train_label'] = training_label_aug.long().to(device)\n",
    "    \n",
    "    # Put all data in test datasets\n",
    "    dataset_kan['test_input'] = input_data[:, [*range(nGstart, nGs)]].to(device)\n",
    "    dataset_kan['test_label'] = symmetry_data.long().to(device)\n",
    "    \n",
    "    n_class = 16\n",
    "    if band_idx == 0:\n",
    "        n_class = 8\n",
    "    model = KAN(width=[9, 24, n_class], grid=5, k=1, seed=1, device=device)\n",
    "    lr = 1\n",
    "    def train_acc():\n",
    "        return torch.mean((torch.argmax(model(dataset_kan['train_input']), dim=1) == dataset_kan['train_label']).type(dtype))\n",
    "    \n",
    "    def test_acc():\n",
    "        return torch.mean((torch.argmax(model(dataset_kan['test_input']), dim=1) == dataset_kan['test_label']).type(dtype))\n",
    "        \n",
    "    results = model.fit(dataset_kan, opt=\"LBFGS\", steps=100, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss(), lr=lr);\n",
    "    model.attribute()\n",
    "    print(\"Train accuracy: \", round(results['train_acc'][-1]*100, 2),  \" Test accuracy: \", round(results['test_acc'][-1]*100, 2))\n",
    "    training_accs_aug.append(round(results['train_acc'][-1]*100, 2))\n",
    "    testing_accs_aug.append(round(results['test_acc'][-1]*100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "26fb3322-0634-496d-9771-7fef5e593ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "plt.scatter(range(0, 11), testing_accs_aug, color=\"red\")\n",
    "plt.scatter(range(0, 11), testing_accs_no_aug, color=\"blue\")\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlim(-1, 10)\n",
    "ax.set_xticks(range(0, 11), [2**(x+3) for x in range(0, 11)] );\n",
    "plt.savefig(\"./figures/Augmentation_accuracy_increase.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
